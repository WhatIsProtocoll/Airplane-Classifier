{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "945fbe66",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c13617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, Conv2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import activations as Ac\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ff6126",
   "metadata": {},
   "source": [
    "# 1. Setup Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43cce5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_path = 'data/classFolders'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bda0bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for class_name in os.listdir(image_folder_path):\n",
    "    class_folder = os.path.join(image_folder_path, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "        for filename in os.listdir(class_folder):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                relative_path = os.path.join(class_name, filename)\n",
    "                data.append({'filename': relative_path, 'family_name': class_name})\n",
    "\n",
    "complete_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2658a5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>family_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A320\\A320_0001_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A320\\A320_0002_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A320\\A320_0003_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A320\\A320_0004_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A320\\A320_0005_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename family_name\n",
       "0  A320\\A320_0001_crop0.jpg        A320\n",
       "1  A320\\A320_0002_crop0.jpg        A320\n",
       "2  A320\\A320_0003_crop0.jpg        A320\n",
       "3  A320\\A320_0004_crop0.jpg        A320\n",
       "4  A320\\A320_0005_crop0.jpg        A320"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53dc4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "family_name\n",
       "A320              200\n",
       "A330              200\n",
       "A340              200\n",
       "ATR-72            200\n",
       "Boeing_737        200\n",
       "Boeing_747        200\n",
       "Boeing_757        200\n",
       "Boeing_767        200\n",
       "Boeing_777        200\n",
       "Boeing_787        200\n",
       "CRJ-700           200\n",
       "Embraer_E-Jet     200\n",
       "A350              199\n",
       "Boeing_737_MAX    199\n",
       "Dash_8            199\n",
       "A380              198\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df['family_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce1d548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "complete_df['label'] = encoder.fit_transform(complete_df['family_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5438e500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>family_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A320\\A320_0001_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A320\\A320_0002_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A320\\A320_0003_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A320\\A320_0004_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A320\\A320_0005_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename family_name  label\n",
       "0  A320\\A320_0001_crop0.jpg        A320      0\n",
       "1  A320\\A320_0002_crop0.jpg        A320      0\n",
       "2  A320\\A320_0003_crop0.jpg        A320      0\n",
       "3  A320\\A320_0004_crop0.jpg        A320      0\n",
       "4  A320\\A320_0005_crop0.jpg        A320      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1252a",
   "metadata": {},
   "source": [
    "# 2. Split Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd42e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2236, 3)\n",
      "Val: (479, 3)\n",
      "Test: (480, 3)\n"
     ]
    }
   ],
   "source": [
    "train, df_temp = train_test_split(\n",
    "    complete_df,\n",
    "    test_size=0.3,\n",
    "    stratify=complete_df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val, test = train_test_split(\n",
    "    df_temp,\n",
    "    test_size=0.5,\n",
    "    stratify=df_temp['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", train.shape)\n",
    "print(\"Val:\", val.shape)\n",
    "print(\"Test:\", test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b9c6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_paths(df, base_path):\n",
    "    return df.filename.apply(lambda x: os.path.join(base_path, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "600f1383",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = build_paths(train, image_folder_path)\n",
    "val_paths = build_paths(val, image_folder_path)\n",
    "test_paths = build_paths(test, image_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "753b680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2236, 16)\n",
      "(479, 16)\n",
      "(480, 16)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train.label)\n",
    "print(train_labels.shape)\n",
    "\n",
    "val_labels = to_categorical(val.label)\n",
    "print(val_labels.shape)\n",
    "\n",
    "test_labels = to_categorical(test.label)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "974df521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporarily split traning set so that we can augment only 70%\n",
    "train_aug, train_plain = train_test_split(\n",
    "    train,\n",
    "    test_size=0.3,\n",
    "    stratify=train['label'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9257f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_paths = train_aug.filename.apply(lambda x: os.path.join(image_folder_path, x))\n",
    "train_plain_paths = train_plain.filename.apply(lambda x: os.path.join(image_folder_path, x))\n",
    "\n",
    "train_aug_labels = tf.keras.utils.to_categorical(train_aug['label'])\n",
    "train_plain_labels = tf.keras.utils.to_categorical(train_plain['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071412a0",
   "metadata": {},
   "source": [
    "# 3. Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca51aacd",
   "metadata": {},
   "source": [
    "## 3.1 Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2faf069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=(224, 224)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, image_size)\n",
    "\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2892854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(image, min_scale=0.3, max_scale=0.7):\n",
    "    scale = tf.random.uniform([], min_scale, max_scale)\n",
    "    h, w = tf.shape(image)[0], tf.shape(image)[1]\n",
    "    new_h = tf.cast(tf.cast(h, tf.float32) * scale, tf.int32)\n",
    "    new_w = tf.cast(tf.cast(w, tf.float32) * scale, tf.int32)\n",
    "\n",
    "    image = tf.image.resize(image, (new_h, new_w))\n",
    "    image = tf.image.resize(image, (h, w))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46c9a4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, 0.1)\n",
    "    tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.random_crop(image, size=[205, 205, 3])\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = downsample(image)\n",
    "\n",
    "    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.03)\n",
    "    image = tf.clip_by_value(image + noise, 0.0, 1.0)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f19c16",
   "metadata": {},
   "source": [
    "## 3.2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04acf106",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epoch_count = 50\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "def mish(x):\n",
    "    return x * K.tanh(Ac.softplus(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81ffba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((train_aug_paths, train_aug_labels))\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .map(augment, num_parallel_calls=AUTO)\n",
    ")\n",
    "\n",
    "train_plain_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((train_plain_paths, train_plain_labels))\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c09e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    train_aug_dataset\n",
    "    .concatenate(train_plain_dataset)\n",
    "    .shuffle(2048)\n",
    "    .repeat()\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "val_dataset = (tf.data.Dataset\n",
    "        .from_tensor_slices((val_paths, val_labels))\n",
    "        .map(decode_image, num_parallel_calls=AUTO)\n",
    "        .batch(batch_size)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((test_paths, test_labels))\n",
    "    .map(decode_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f319df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_model(model, batch_size, EPOCHS):\n",
    "\n",
    "    n_steps = train_labels.shape[0] // batch_size\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor = 'val_loss',\n",
    "        factor = 0.5,\n",
    "        patience = 3,\n",
    "        verbose = 1,\n",
    "        min_lr = 0.0001)\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    Model = model\n",
    "    history = Model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch = n_steps,\n",
    "        epochs = epoch_count,\n",
    "        validation_data = val_dataset,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose = 1)\n",
    "\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\sande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74836368/74836368 [==============================] - 13s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 7, 7, 128)         2211968   \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 128)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              132096    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1024)              4096      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                4112      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21333456 (81.38 MB)\n",
      "Trainable params: 21100816 (80.49 MB)\n",
      "Non-trainable params: 232640 (908.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def mish(x):\n",
    "    return x * K.tanh(Ac.softplus(x))\n",
    "\n",
    "base_model = DenseNet201(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "base_model.trainable = True\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, activation=mish),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation=mish),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation=mish),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = SGD()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e2510e",
   "metadata": {},
   "source": [
    "# 4. Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78223ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\sande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\sande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training')\n",
    "model = Train_model(model, batch_size, epoch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689382e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9fec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('path/modelname.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
