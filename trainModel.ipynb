{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, Conv2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import activations as Ac\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_path = 'data/classFolders'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for class_name in os.listdir(image_folder_path):\n",
    "    class_folder = os.path.join(image_folder_path, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "        for filename in os.listdir(class_folder):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                relative_path = os.path.join(class_name, filename)\n",
    "                data.append({'filename': relative_path, 'family_name': class_name})\n",
    "\n",
    "complete_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>family_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A320\\A320_0001_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A320\\A320_0002_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A320\\A320_0003_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A320\\A320_0004_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A320\\A320_0005_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename family_name\n",
       "0  A320\\A320_0001_crop0.jpg        A320\n",
       "1  A320\\A320_0002_crop0.jpg        A320\n",
       "2  A320\\A320_0003_crop0.jpg        A320\n",
       "3  A320\\A320_0004_crop0.jpg        A320\n",
       "4  A320\\A320_0005_crop0.jpg        A320"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "family_name\n",
       "A320              200\n",
       "A330              200\n",
       "A340              200\n",
       "ATR-72            200\n",
       "Boeing_737        200\n",
       "Boeing_767        200\n",
       "Boeing_757        200\n",
       "Boeing_747        200\n",
       "Boeing_787        200\n",
       "CRJ-700           200\n",
       "Embraer_E-Jet     200\n",
       "Boeing_777        200\n",
       "A350              199\n",
       "Boeing_737_MAX    199\n",
       "Dash_8            199\n",
       "A380              198\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "complete_df['family_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "complete_df['label'] = encoder.fit_transform(complete_df['family_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>family_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A320\\A320_0001_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A320\\A320_0002_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A320\\A320_0003_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A320\\A320_0004_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A320\\A320_0005_crop0.jpg</td>\n",
       "      <td>A320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename family_name  label\n",
       "0  A320\\A320_0001_crop0.jpg        A320      0\n",
       "1  A320\\A320_0002_crop0.jpg        A320      0\n",
       "2  A320\\A320_0003_crop0.jpg        A320      0\n",
       "3  A320\\A320_0004_crop0.jpg        A320      0\n",
       "4  A320\\A320_0005_crop0.jpg        A320      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2236, 3)\n",
      "Val: (479, 3)\n",
      "Test: (480, 3)\n"
     ]
    }
   ],
   "source": [
    "train, df_temp = train_test_split(\n",
    "    complete_df,\n",
    "    test_size=0.3,\n",
    "    stratify=complete_df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val, test = train_test_split(\n",
    "    df_temp,\n",
    "    test_size=0.5,\n",
    "    stratify=df_temp['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", train.shape)\n",
    "print(\"Val:\", val.shape)\n",
    "print(\"Test:\", test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_paths(df, base_path):\n",
    "    return df.filename.apply(lambda x: os.path.join(base_path, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = build_paths(train, image_folder_path)\n",
    "val_paths = build_paths(val, image_folder_path)\n",
    "test_paths = build_paths(test, image_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2236, 16)\n",
      "(479, 16)\n",
      "(480, 16)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_categorical(train.label)\n",
    "print(train_labels.shape)\n",
    "\n",
    "val_labels = to_categorical(val.label)\n",
    "print(val_labels.shape)\n",
    "\n",
    "test_labels = to_categorical(test.label)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporarily split traning set so that we can augment only 70%\n",
    "train_aug, train_plain = train_test_split(\n",
    "    train,\n",
    "    test_size=0.3,\n",
    "    stratify=train['label'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_paths = train_aug.filename.apply(lambda x: os.path.join(image_folder_path, x))\n",
    "train_plain_paths = train_plain.filename.apply(lambda x: os.path.join(image_folder_path, x))\n",
    "\n",
    "train_aug_labels = tf.keras.utils.to_categorical(train_aug['label'])\n",
    "train_plain_labels = tf.keras.utils.to_categorical(train_plain['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=(224, 224)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, image_size)\n",
    "\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(image, min_scale=0.3, max_scale=0.7):\n",
    "    scale = tf.random.uniform([], min_scale, max_scale)\n",
    "    h, w = tf.shape(image)[0], tf.shape(image)[1]\n",
    "    new_h = tf.cast(tf.cast(h, tf.float32) * scale, tf.int32)\n",
    "    new_w = tf.cast(tf.cast(w, tf.float32) * scale, tf.int32)\n",
    "\n",
    "    image = tf.image.resize(image, (new_h, new_w))\n",
    "    image = tf.image.resize(image, (h, w))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, 0.1)\n",
    "    tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.random_crop(image, size=[205, 205, 3])\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = downsample(image)\n",
    "\n",
    "    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.03)\n",
    "    image = tf.clip_by_value(image + noise, 0.0, 1.0)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epoch_count = 50\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "def mish(x):\n",
    "    return x * K.tanh(Ac.softplus(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((train_aug_paths, train_aug_labels))\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .map(augment, num_parallel_calls=AUTO)\n",
    ")\n",
    "\n",
    "train_plain_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((train_plain_paths, train_plain_labels))\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    train_aug_dataset\n",
    "    .concatenate(train_plain_dataset)\n",
    "    .shuffle(2048)\n",
    "    .repeat()\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "val_dataset = (tf.data.Dataset\n",
    "        .from_tensor_slices((val_paths, val_labels))\n",
    "        .map(decode_image, num_parallel_calls=AUTO)\n",
    "        .batch(batch_size)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((test_paths, test_labels))\n",
    "    .map(decode_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_model(model, batch_size, EPOCHS):\n",
    "\n",
    "    n_steps = train_labels.shape[0] // batch_size\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor = 'val_loss',\n",
    "        factor = 0.5,\n",
    "        patience = 3,\n",
    "        verbose = 1,\n",
    "        min_lr = 0.0001)\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    Model = model\n",
    "    history = Model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch = n_steps,\n",
    "        epochs = epoch_count,\n",
    "        validation_data = val_dataset,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose = 1)\n",
    "\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ densenet201 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">18,321,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,211,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">132,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,112</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ densenet201 (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1920\u001b[0m)     │    \u001b[38;5;34m18,321,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │     \u001b[38;5;34m2,211,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m132,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m4,112\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,333,456</span> (81.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,333,456\u001b[0m (81.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,100,816</span> (80.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,100,816\u001b[0m (80.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">232,640</span> (908.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m232,640\u001b[0m (908.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = DenseNet201(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "base_model.trainable = True\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, activation=mish),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation=mish),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation=mish),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = SGD()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch 1/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m817s\u001b[0m 6s/step - accuracy: 0.0935 - loss: 3.6210 - val_accuracy: 0.0898 - val_loss: 2.7649\n",
      "Epoch 2/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m772s\u001b[0m 6s/step - accuracy: 0.1247 - loss: 3.0624 - val_accuracy: 0.2213 - val_loss: 2.4824\n",
      "Epoch 3/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m764s\u001b[0m 6s/step - accuracy: 0.2409 - loss: 2.5090 - val_accuracy: 0.2589 - val_loss: 2.9681\n",
      "Epoch 4/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 5s/step - accuracy: 0.3673 - loss: 1.9739 - val_accuracy: 0.3841 - val_loss: 1.9841\n",
      "Epoch 5/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 5s/step - accuracy: 0.5071 - loss: 1.5483 - val_accuracy: 0.5637 - val_loss: 1.3779\n",
      "Epoch 6/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m708s\u001b[0m 5s/step - accuracy: 0.6052 - loss: 1.2077 - val_accuracy: 0.6096 - val_loss: 1.2946\n",
      "Epoch 7/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m693s\u001b[0m 5s/step - accuracy: 0.6721 - loss: 0.9677 - val_accuracy: 0.6848 - val_loss: 1.0676\n",
      "Epoch 8/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m688s\u001b[0m 5s/step - accuracy: 0.7414 - loss: 0.7956 - val_accuracy: 0.6597 - val_loss: 1.2578\n",
      "Epoch 9/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 5s/step - accuracy: 0.8106 - loss: 0.5973 - val_accuracy: 0.6806 - val_loss: 1.0614\n",
      "Epoch 10/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m730s\u001b[0m 5s/step - accuracy: 0.8313 - loss: 0.5100 - val_accuracy: 0.7035 - val_loss: 1.1274\n",
      "Epoch 11/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 5s/step - accuracy: 0.8650 - loss: 0.4277 - val_accuracy: 0.7203 - val_loss: 1.0546\n",
      "Epoch 12/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 5s/step - accuracy: 0.8778 - loss: 0.3725 - val_accuracy: 0.7077 - val_loss: 1.0536\n",
      "Epoch 13/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 5s/step - accuracy: 0.8937 - loss: 0.3386 - val_accuracy: 0.6889 - val_loss: 1.1992\n",
      "Epoch 14/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 5s/step - accuracy: 0.9211 - loss: 0.2338 - val_accuracy: 0.7495 - val_loss: 1.0092\n",
      "Epoch 15/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m687s\u001b[0m 5s/step - accuracy: 0.9319 - loss: 0.2366 - val_accuracy: 0.7119 - val_loss: 1.1130\n",
      "Epoch 16/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 5s/step - accuracy: 0.9359 - loss: 0.1824 - val_accuracy: 0.7182 - val_loss: 1.2789\n",
      "Epoch 17/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m679s\u001b[0m 5s/step - accuracy: 0.9313 - loss: 0.2163 - val_accuracy: 0.7724 - val_loss: 0.9914\n",
      "Epoch 18/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 5s/step - accuracy: 0.9352 - loss: 0.1891 - val_accuracy: 0.7578 - val_loss: 1.0029\n",
      "Epoch 19/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 5s/step - accuracy: 0.9535 - loss: 0.1635 - val_accuracy: 0.7787 - val_loss: 0.9647\n",
      "Epoch 20/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m679s\u001b[0m 5s/step - accuracy: 0.9574 - loss: 0.1323 - val_accuracy: 0.7578 - val_loss: 1.0107\n",
      "Epoch 21/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 5s/step - accuracy: 0.9409 - loss: 0.1675 - val_accuracy: 0.7328 - val_loss: 1.1219\n",
      "Epoch 22/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 5s/step - accuracy: 0.9663 - loss: 0.1252 - val_accuracy: 0.7766 - val_loss: 0.9795\n",
      "Epoch 23/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m679s\u001b[0m 5s/step - accuracy: 0.9617 - loss: 0.1160 - val_accuracy: 0.7871 - val_loss: 0.8896\n",
      "Epoch 24/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 5s/step - accuracy: 0.9768 - loss: 0.0872 - val_accuracy: 0.7829 - val_loss: 0.9816\n",
      "Epoch 25/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 5s/step - accuracy: 0.9673 - loss: 0.1089 - val_accuracy: 0.7745 - val_loss: 0.9316\n",
      "Epoch 26/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 5s/step - accuracy: 0.9625 - loss: 0.1130 - val_accuracy: 0.7996 - val_loss: 0.9335\n",
      "Epoch 27/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 5s/step - accuracy: 0.9651 - loss: 0.1126 - val_accuracy: 0.7453 - val_loss: 1.0758\n",
      "Epoch 28/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 5s/step - accuracy: 0.9668 - loss: 0.0966 - val_accuracy: 0.7996 - val_loss: 0.8804\n",
      "Epoch 29/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 5s/step - accuracy: 0.9846 - loss: 0.0707 - val_accuracy: 0.7850 - val_loss: 0.9838\n",
      "Epoch 30/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 5s/step - accuracy: 0.9780 - loss: 0.0813 - val_accuracy: 0.7683 - val_loss: 0.9629\n",
      "Epoch 31/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 5s/step - accuracy: 0.9736 - loss: 0.0760 - val_accuracy: 0.7662 - val_loss: 1.0380\n",
      "Epoch 32/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 5s/step - accuracy: 0.9810 - loss: 0.0732 - val_accuracy: 0.7850 - val_loss: 0.9051\n",
      "Epoch 33/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 5s/step - accuracy: 0.9747 - loss: 0.0656 - val_accuracy: 0.8184 - val_loss: 0.8051\n",
      "Epoch 34/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m752s\u001b[0m 5s/step - accuracy: 0.9869 - loss: 0.0531 - val_accuracy: 0.8058 - val_loss: 0.8344\n",
      "Epoch 35/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m716s\u001b[0m 5s/step - accuracy: 0.9806 - loss: 0.0637 - val_accuracy: 0.8163 - val_loss: 0.8958\n",
      "Epoch 36/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m717s\u001b[0m 5s/step - accuracy: 0.9829 - loss: 0.0517 - val_accuracy: 0.7662 - val_loss: 1.0483\n",
      "Epoch 37/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m672s\u001b[0m 5s/step - accuracy: 0.9786 - loss: 0.0628 - val_accuracy: 0.8017 - val_loss: 0.9202\n",
      "Epoch 38/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m671s\u001b[0m 5s/step - accuracy: 0.9781 - loss: 0.0763 - val_accuracy: 0.7766 - val_loss: 0.9429\n"
     ]
    }
   ],
   "source": [
    "print('Training')\n",
    "model = Train_model(model, batch_size, epoch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.8339 - loss: 0.8497\n",
      "Test Accuracy: 0.8229\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('path/modelname.keras')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
